"""
ç›´æ¥é›†æˆçš„ä¸‰è½®Promptå¯¹æ¯”å®éªŒè„šæœ¬
åŠŸèƒ½ï¼šåœ¨ä¸€ä¸ªPythonè¿›ç¨‹ä¸­ç›´æ¥è¿è¡Œä¸‰è½®å®éªŒï¼Œæ— éœ€è°ƒç”¨å­è¿›ç¨‹
ä½¿ç”¨æ–¹å¼ï¼špython direct_run_experiments.py
"""
import os
import sys
import json

# å°†GroundingDINOé¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
PROJECT_ROOT = "D:/groundingdino_work/GroundingDINO-main"
sys.path.append(PROJECT_ROOT)

DEMO_DIR = "D:/groundingdino_work/GroundingDINO-main/demo"
OUTPUT_DIR = "D:/groundingdino_work/GroundingDINO-main/results"

def run_single_prompt_experiment(prompt_round):
    """åœ¨åŒä¸€è¿›ç¨‹ä¸­ç›´æ¥è¿è¡Œå•è½®å®éªŒ"""
    print(f"\n{'='*70}")
    print(f"ğŸš€ å¼€å§‹{prompt_round}è½®å®éªŒï¼ˆç›´æ¥é›†æˆæ¨¡å¼ï¼‰")
    print(f"{'='*70}\n")
    
    # è®¾ç½®PROMPT_ROUND
    os.environ["PROMPT_ROUND_OVERRIDE"] = prompt_round
    
    # ä¿®æ”¹inference_coco.py
    inference_file = os.path.join(DEMO_DIR, "inference_coco.py")
    
    print(f"ğŸ“ æ­£åœ¨ä¿®æ”¹ inference_coco.py...")
    with open(inference_file, "r", encoding="utf-8") as f:
        content = f.read()
    
    # æ›¿æ¢æ‰€æœ‰PROMPT_ROUNDè®¾ç½®
    for old_round in ["prompt1", "prompt2", "prompt3"]:
        content = content.replace(
            f'PROMPT_ROUND = "{old_round}"',
            f'PROMPT_ROUND = "{prompt_round}"'
        )
    
    with open(inference_file, "w", encoding="utf-8") as f:
        f.write(content)
    
    print(f"âœ… å·²è®¾ç½®Promptè½®æ¬¡ä¸ºï¼š{prompt_round}")
    
    # ä¿®æ”¹eval_coco.py
    eval_file = os.path.join(DEMO_DIR, "eval_coco.py")
    
    print(f"ğŸ“ æ­£åœ¨ä¿®æ”¹ eval_coco.py...")
    with open(eval_file, "r", encoding="utf-8") as f:
        eval_content = f.read()
    
    for old_round in ["prompt1", "prompt2", "prompt3"]:
        eval_content = eval_content.replace(
            f'PROMPT_VERSION = "{old_round}"',
            f'PROMPT_VERSION = "{prompt_round}"'
        )
    
    with open(eval_file, "w", encoding="utf-8") as f:
        f.write(eval_content)
    
    print(f"âœ… å·²è®¾ç½®evalè¯„æµ‹Promptç‰ˆæœ¬ä¸ºï¼š{prompt_round}")
    
    # Step 1: è¿è¡Œæ¨ç†
    print(f"\nğŸ“ è¿è¡Œæ¨ç†è„šæœ¬ï¼ˆè¿™å¯èƒ½éœ€è¦30-120åˆ†é’Ÿï¼‰...")
    print("=" * 70)
    
    # ç›´æ¥å¯¼å…¥å¹¶æ‰§è¡Œinference_coco.pyçš„mainå‡½æ•°
    try:
        # ä¿å­˜å½“å‰å·¥ä½œç›®å½•
        original_dir = os.getcwd()
        os.chdir(DEMO_DIR)
        
        # æ¸…é™¤æ‰€æœ‰inference_cocoå’Œeval_cocoç›¸å…³çš„æ¨¡å—ç¼“å­˜
        modules_to_remove = [m for m in list(sys.modules.keys()) 
                            if 'inference_coco' in m or 'eval_coco' in m or 'groundingdino' in m]
        for module in modules_to_remove:
            try:
                del sys.modules[module]
            except:
                pass
        
        # é‡æ–°æ·»åŠ é¡¹ç›®è·¯å¾„
        PROJECT_ROOT = os.path.join(DEMO_DIR, "..")
        if PROJECT_ROOT not in sys.path:
            sys.path.insert(0, PROJECT_ROOT)
        
        # å¯¼å…¥å¹¶æ‰§è¡Œæ¨ç†è„šæœ¬
        print(f"ğŸ”„ å¯¼å…¥ inference_coco æ¨¡å—...")
        import importlib
        if 'inference_coco' in sys.modules:
            importlib.reload(sys.modules['inference_coco'])
        else:
            import inference_coco
        
        print(f"ğŸ”„ è¿è¡Œæ¨ç† main() å‡½æ•°...")
        inference_coco.main()
        
        # æ¢å¤åŸå·¥ä½œç›®å½•
        os.chdir(original_dir)
        
        print("\n" + "=" * 70)
        print(f"âœ… {prompt_round}è½®æ¨ç†å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ {prompt_round}è½®æ¨ç†å¤±è´¥ï¼š{str(e)}")
        print(f"   é”™è¯¯ç±»å‹ï¼š{type(e).__name__}")
        import traceback
        traceback.print_exc()
        os.chdir(original_dir)
        return False
    
    # Step 2: è¿è¡Œè¯„æµ‹
    print(f"\nğŸ“ è¿è¡Œè¯„æµ‹è„šæœ¬ï¼ˆè¿™å¯èƒ½éœ€è¦10-20åˆ†é’Ÿï¼‰...")
    print("=" * 70)
    
    try:
        # ä¿å­˜å½“å‰å·¥ä½œç›®å½•
        original_dir = os.getcwd()
        os.chdir(DEMO_DIR)
        
        # æ¸…é™¤ä¹‹å‰å¯¼å…¥çš„æ¨¡å—ç¼“å­˜
        modules_to_remove = [m for m in list(sys.modules.keys()) 
                            if 'eval_coco' in m]
        for module in modules_to_remove:
            try:
                del sys.modules[module]
            except:
                pass
        
        # é‡æ–°æ·»åŠ é¡¹ç›®è·¯å¾„
        PROJECT_ROOT = os.path.join(DEMO_DIR, "..")
        if PROJECT_ROOT not in sys.path:
            sys.path.insert(0, PROJECT_ROOT)
        
        # å¯¼å…¥å¹¶æ‰§è¡Œè¯„æµ‹è„šæœ¬
        print(f"ğŸ”„ å¯¼å…¥ eval_coco æ¨¡å—...")
        import importlib
        if 'eval_coco' in sys.modules:
            importlib.reload(sys.modules['eval_coco'])
        else:
            import eval_coco
        
        print(f"ğŸ”„ è¿è¡Œè¯„æµ‹ main() å‡½æ•°...")
        eval_coco.main()
        
        # æ¢å¤åŸå·¥ä½œç›®å½•
        os.chdir(original_dir)
        
        print("\n" + "=" * 70)
        print(f"âœ… {prompt_round}è½®è¯„æµ‹å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ {prompt_round}è½®è¯„æµ‹å¤±è´¥ï¼š{str(e)}")
        print(f"   é”™è¯¯ç±»å‹ï¼š{type(e).__name__}")
        import traceback
        traceback.print_exc()
        os.chdir(original_dir)
        return False

def check_results():
    """æ£€æŸ¥ä¸‰è½®ç»“æœæ˜¯å¦å®Œæˆ"""
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æ£€æŸ¥ä¸‰è½®å®éªŒç»“æœ")
    print(f"{'='*70}\n")
    
    results_status = {}
    
    for prompt_round in ["prompt1", "prompt2", "prompt3"]:
        seen_file = os.path.join(OUTPUT_DIR, f"coco_seen_400imgs_{prompt_round}.json")
        unseen_file = os.path.join(OUTPUT_DIR, f"coco_unseen_100imgs_{prompt_round}.json")
        eval_txt = os.path.join(OUTPUT_DIR, f"coco_eval_result_{prompt_round}.txt")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”éç©º
        seen_ok = os.path.exists(seen_file) and os.path.getsize(seen_file) > 100
        unseen_ok = os.path.exists(unseen_file) and os.path.getsize(unseen_file) > 100
        eval_ok = os.path.exists(eval_txt) and os.path.getsize(eval_txt) > 100
        
        if seen_ok:
            with open(seen_file, "r") as f:
                seen_count = len(json.load(f))
            seen_info = f"âœ… SEENæ£€æµ‹æ¡†: {seen_count}ä¸ª"
        else:
            seen_info = "âŒ SEENæ£€æµ‹æ¡†: ç¼ºå¤±"
        
        if unseen_ok:
            with open(unseen_file, "r") as f:
                unseen_count = len(json.load(f))
            unseen_info = f"âœ… UNSEENæ£€æµ‹æ¡†: {unseen_count}ä¸ª"
        else:
            unseen_info = "âŒ UNSEENæ£€æµ‹æ¡†: ç¼ºå¤±"
        
        eval_info = "âœ… è¯„æµ‹ç»“æœ: å®Œæˆ" if eval_ok else "âŒ è¯„æµ‹ç»“æœ: ç¼ºå¤±"
        
        all_ok = seen_ok and unseen_ok and eval_ok
        status = "âœ… å®Œæˆ" if all_ok else "â³ æœªå®Œæˆ"
        
        print(f"{prompt_round}:")
        print(f"  {status}")
        print(f"  {seen_info}")
        print(f"  {unseen_info}")
        print(f"  {eval_info}\n")
        
        results_status[prompt_round] = all_ok
    
    return results_status

def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("ğŸ¯ GroundingDINO Promptå·¥ç¨‹å¯¹æ¯”å®éªŒï¼ˆä¸‰è½®ç›´æ¥é›†æˆæ¨¡å¼ï¼‰")
    print("="*70)
    
    print("\nğŸ“‹ å®éªŒè®¡åˆ’ï¼š")
    print("  Round 1 (prompt1): çº¯ç±»å (Pure Class Names)")
    print("  Round 2 (prompt2): æ¨¡æ¿å¥ (Template Sentences)")
    print("  Round 3 (prompt3): ç»†ç²’åº¦æè¿° (Fine-grained Descriptions)")
    
    print("\nâ±ï¸ é¢„è®¡è€—æ—¶ï¼š60-180åˆ†é’Ÿï¼ˆå–å†³äºGPU/CPUæ€§èƒ½ï¼‰")
    print("ğŸ“Œ æ³¨æ„ï¼šè„šæœ¬ä¼šæ˜¾ç¤ºè¯¦ç»†çš„è¿›åº¦ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¿›åº¦æ¡å’Œè¾“å‡ºæ—¥å¿—\n")
    
    user_input = input("æ˜¯å¦å¼€å§‹è¿è¡Œä¸‰è½®å®éªŒï¼Ÿ(yes/no): ").strip().lower()
    if user_input != "yes":
        print("âŒ å·²å–æ¶ˆå®éªŒ")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"\nğŸ“ ç»“æœç›®å½•: {OUTPUT_DIR}")
    
    # è¿è¡Œä¸‰è½®å®éªŒ
    print("\n" + "="*70)
    print("å¼€å§‹æ‰§è¡Œä¸‰è½®å®éªŒ...")
    print("="*70)
    
    completed = []
    failed = []
    
    for i, prompt_round in enumerate(["prompt1", "prompt2", "prompt3"], 1):
        print(f"\n[{i}/3] è¿è¡Œ{prompt_round}è½®å®éªŒ")
        try:
            success = run_single_prompt_experiment(prompt_round)
            if success:
                completed.append(prompt_round)
            else:
                failed.append(prompt_round)
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†å®éªŒ")
            failed.append(prompt_round)
            break
        except Exception as e:
            print(f"\nâŒ {prompt_round}è½®å®éªŒå¼‚å¸¸: {str(e)}")
            failed.append(prompt_round)
    
    # æ£€æŸ¥å¹¶æ˜¾ç¤ºç»“æœ
    check_results()
    
    # æœ€ç»ˆæ€»ç»“
    print("\n" + "="*70)
    print("ğŸ“Œ å®éªŒæ‰§è¡Œæ€»ç»“")
    print("="*70)
    
    if completed:
        print(f"\nâœ… æˆåŠŸå®Œæˆ: {len(completed)}/3 è½®")
        print(f"   è½®æ¬¡: {', '.join(completed)}")
    
    if failed:
        print(f"\nâŒ å¤±è´¥: {len(failed)}/3 è½®")
        print(f"   è½®æ¬¡: {', '.join(failed)}")
        print("\n   æ•…éšœæ’æŸ¥å»ºè®®ï¼š")
        print("   1. æŸ¥çœ‹ä¸Šè¿°é”™è¯¯æ—¥å¿—")
        print("   2. æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")
        print("   3. æ£€æŸ¥COCOæ•°æ®é›†æ˜¯å¦å®Œæ•´")
        print("   4. é‡æ–°è¿è¡Œå•ä¸ªè½®æ¬¡è¿›è¡Œè°ƒè¯•")
    
    if set(completed) == {"prompt1", "prompt2", "prompt3"}:
        print("\nâœ… æ‰€æœ‰ä¸‰è½®å®éªŒå‡æˆåŠŸå®Œæˆï¼")
        print("\nğŸ‰ ä¸‹ä¸€æ­¥ï¼š")
        print("   1. ç”Ÿæˆå¯¹æ¯”åˆ†æï¼špython compare_prompt_results.py")
        print("   2. æŸ¥çœ‹å¯¹æ¯”è¡¨æ ¼ï¼šresults/prompt_comparison_summary.csv")
        print("   3. æŸ¥çœ‹å¯¹æ¯”æŠ¥å‘Šï¼šresults/prompt_comparison_analysis.txt")
    
    print("="*70 + "\n")

if __name__ == "__main__":
    main()
