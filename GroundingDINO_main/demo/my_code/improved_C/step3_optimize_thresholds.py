# step3_optimize_thresholds.py (ä¿®å¤ç‰ˆ)
"""
ç¬¬3æ­¥ï¼šåŸºäºéªŒè¯é›†çš„åŸå§‹é¢„æµ‹ç»“æœï¼Œä¸ºæ¯ä¸ªç±»åˆ«ç»Ÿè®¡æœ€ä¼˜é˜ˆå€¼
æ–¹æ¡ˆCï¼šæ ¹æ®æ¯ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†å¸ƒåŠ¨æ€é€‰æ‹©é˜ˆå€¼
"""
import os
import json
import numpy as np
from collections import defaultdict
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
from tabulate import tabulate

# é…ç½®
BASE_DIR = "D:/groundingdino_work/GroundingDINO-main"
ANNO_PATH = os.path.join(BASE_DIR, "data/coco/annotations/instances_val2017.json")
OUTPUT_DIR = os.path.join(BASE_DIR, "results")

# ç±»åˆ«åç§°æ˜ å°„
CLASS_NAMES = {
    1: "person", 2: "bicycle", 3: "car", 4: "motorcycle", 5: "airplane",
    6: "bus", 7: "train", 8: "truck", 9: "boat", 10: "traffic light",
    11: "fire hydrant", 13: "stop sign", 14: "parking meter", 15: "bench",
    16: "bird", 17: "cat", 18: "dog", 19: "horse", 20: "sheep",
    21: "cow", 22: "elephant", 23: "bear", 24: "zebra", 25: "giraffe",
    27: "backpack", 28: "umbrella", 31: "handbag", 32: "tie", 33: "suitcase",
    34: "frisbee", 35: "skis", 36: "snowboard", 37: "sports ball", 38: "kite",
    39: "baseball bat", 40: "baseball glove", 41: "skateboard", 42: "surfboard",
    43: "tennis racket", 44: "bottle", 46: "wine glass", 47: "cup", 48: "fork",
    49: "knife", 50: "spoon", 51: "bowl", 62: "chair", 63: "couch",
    64: "potted plant", 65: "bed", 67: "dining table", 70: "toilet",
    72: "tv", 73: "laptop", 74: "mouse", 75: "remote", 76: "keyboard",
    77: "cell phone", 78: "microwave", 79: "oven", 80: "toaster",
    87: "scissors", 88: "teddy bear", 89: "hair drier", 90: "toothbrush"
}

# SEENç±»åˆ«ID
SEEN_CLS_IDS = list(CLASS_NAMES.keys())

# é…ç½®å‚æ•°
DEFAULT_THRESHOLD = 0.15  # é»˜è®¤é˜ˆå€¼
OPTIMIZE_THRESHOLD = 0.2  # æœ€é«˜ç½®ä¿¡åº¦å¤§äºæ­¤å€¼æ‰è¿›è¡Œä¼˜åŒ–
MIN_BOXES = 5  # æœ€å°‘æ£€æµ‹æ¡†æ•°

def evaluate_at_threshold(coco_gt, raw_dets, cls_id, threshold):
    """åœ¨æŒ‡å®šé˜ˆå€¼ä¸‹è¯„ä¼°æŸä¸ªç±»åˆ«çš„æ€§èƒ½"""
    filtered_dets = [d for d in raw_dets if d['score'] >= threshold]
    
    if len(filtered_dets) == 0:
        return {'ap': 0.0, 'ar': 0.0, 'f1': 0.0}
    
    try:
        coco_dt = coco_gt.loadRes(filtered_dets)
        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')
        coco_eval.params.catIds = [cls_id]
        coco_eval.params.imgIds = list(set([d['image_id'] for d in filtered_dets]))
        coco_eval.evaluate()
        coco_eval.accumulate()
        
        prec = coco_eval.eval['precision'][0, :, 0, 0, 2]
        rec = coco_eval.eval['recall'][0, :, 0, 2]
        
        prec = prec[prec > -1]
        rec = rec[rec > -1]
        
        if len(prec) > 0 and len(rec) > 0:
            avg_prec = np.mean(prec)
            avg_rec = np.mean(rec)
            
            if avg_prec + avg_rec > 0:
                f1 = 2 * avg_prec * avg_rec / (avg_prec + avg_rec)
                return {
                    'ap': avg_prec,
                    'ar': avg_rec,
                    'f1': f1
                }
        
        return {'ap': 0.0, 'ar': 0.0, 'f1': 0.0}
    
    except Exception as e:
        print(f"  è¯„ä¼°å‡ºé”™: {e}")
        return {'ap': 0.0, 'ar': 0.0, 'f1': 0.0}

def optimize_thresholds_dynamic():
    """åŠ¨æ€é˜ˆå€¼ç­–ç•¥ï¼šæ ¹æ®æ¯ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†å¸ƒè‡ªåŠ¨é€‰æ‹©"""
    print("=" * 60)
    print("ç¬¬3æ­¥ï¼šåŠ¨æ€é˜ˆå€¼ä¼˜åŒ–ï¼ˆæ–¹æ¡ˆCï¼‰")
    print("=" * 60)
    print(f"é»˜è®¤é˜ˆå€¼: {DEFAULT_THRESHOLD}")
    print(f"ä¼˜åŒ–é˜ˆå€¼çº¿: {OPTIMIZE_THRESHOLD}")
    print(f"æœ€å°‘æ¡†æ•°: {MIN_BOXES}")
    print("=" * 60)
    
    # åŠ è½½COCO GT
    print("\nåŠ è½½COCOæ ‡æ³¨...")
    coco_gt = COCO(ANNO_PATH)
    
    # åŠ è½½åŸå§‹é¢„æµ‹ç»“æœ
    raw_path = os.path.join(OUTPUT_DIR, 'raw_predictions_val.json')
    if not os.path.exists(raw_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {raw_path}")
        print("è¯·å…ˆè¿è¡Œ step2_collect_raw_predictions.py")
        return
    
    with open(raw_path, 'r') as f:
        raw_data = json.load(f)
    
    raw_dets = raw_data['detections']
    print(f"åŸå§‹æ£€æµ‹æ¡†æ€»æ•°: {len(raw_dets)}")
    
    # æŒ‰ç±»åˆ«åˆ†ç»„
    cls_dets = defaultdict(list)
    for det in raw_dets:
        cls_dets[det['category_id']].append(det)
    
    print(f"æœ‰æ£€æµ‹ç»“æœçš„ç±»åˆ«æ•°: {len(cls_dets)}")
    
    # é˜ˆå€¼æ‰«æèŒƒå›´
    scan_thresholds = np.arange(0.05, 0.31, 0.02)  # 0.05åˆ°0.30ï¼Œæ­¥é•¿0.02
    
    optimal_thresholds = {}
    analysis_results = []
    
    # ç»Ÿè®¡ä¿¡æ¯
    optimize_count = 0
    medium_count = 0
    low_count = 0
    no_box_count = 0
    
    high_conf_classes = []  # è®°å½•é«˜ç½®ä¿¡åº¦ç±»åˆ«
    
    for cls_id in SEEN_CLS_IDS:
        cls_name = CLASS_NAMES.get(cls_id, f"Unknown-{cls_id}")
        dets = cls_dets.get(cls_id, [])
        
        print(f"\nå¤„ç†ç±»åˆ«: {cls_name} (ID: {cls_id})")
        print(f"  åŸå§‹æ£€æµ‹æ¡†æ•°: {len(dets)}")
        
        # æƒ…å†µ1ï¼šæ²¡æœ‰æ£€æµ‹æ¡†
        if len(dets) == 0:
            print(f"  âš ï¸ æ— æ£€æµ‹æ¡†ï¼Œä½¿ç”¨é»˜è®¤é˜ˆå€¼ {DEFAULT_THRESHOLD}")
            optimal_thresholds[str(cls_id)] = DEFAULT_THRESHOLD
            analysis_results.append([
                cls_id, cls_name, 0, DEFAULT_THRESHOLD, 
                0.0, 0.0, 0.0, "æ— æ£€æµ‹æ¡†"
            ])
            no_box_count += 1
            continue
        
        # è®¡ç®—è¯¥ç±»åˆ«æ‰€æœ‰æ£€æµ‹æ¡†çš„ç½®ä¿¡åº¦
        scores = [d['score'] for d in dets]
        max_score = max(scores)
        mean_score = np.mean(scores)
        
        print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_score:.4f}, å¹³å‡ç½®ä¿¡åº¦: {mean_score:.4f}")
        
        # æƒ…å†µ2ï¼šæ£€æµ‹æ¡†å¤ªå°‘
        if len(dets) < MIN_BOXES:
            print(f"  âš ï¸ æ£€æµ‹æ¡†å¤ªå°‘ ({len(dets)} < {MIN_BOXES})ï¼Œä½¿ç”¨é»˜è®¤é˜ˆå€¼ {DEFAULT_THRESHOLD}")
            optimal_thresholds[str(cls_id)] = DEFAULT_THRESHOLD
            analysis_results.append([
                cls_id, cls_name, len(dets), DEFAULT_THRESHOLD,
                0.0, 0.0, 0.0, "æ¡†å¤ªå°‘"
            ])
            low_count += 1
            continue
        
        # æƒ…å†µ3ï¼šæœ€é«˜ç½®ä¿¡åº¦å¾ˆä½ (<0.1)
        if max_score < 0.1:
            print(f"  âš ï¸ æœ€é«˜ç½®ä¿¡åº¦ < 0.1ï¼Œä½¿ç”¨é»˜è®¤é˜ˆå€¼ {DEFAULT_THRESHOLD}")
            optimal_thresholds[str(cls_id)] = DEFAULT_THRESHOLD
            analysis_results.append([
                cls_id, cls_name, len(dets), DEFAULT_THRESHOLD,
                0.0, 0.0, 0.0, "ä½ç½®ä¿¡åº¦"
            ])
            low_count += 1
            continue
        
        # æƒ…å†µ4ï¼šæœ€é«˜ç½®ä¿¡åº¦ä¸­ç­‰ (0.1-0.2)
        if max_score < OPTIMIZE_THRESHOLD:
            # ç”¨0.1ä½œä¸ºé˜ˆå€¼ï¼Œå¯èƒ½æ•æ‰åˆ°ä¸€äº›æœ‰ç”¨æ¡†
            suggested_thr = 0.1
            print(f"  â„¹ï¸ æœ€é«˜ç½®ä¿¡åº¦ {max_score:.3f} åœ¨ 0.1-0.2 ä¹‹é—´ï¼Œä½¿ç”¨é˜ˆå€¼ 0.1")
            
            # éªŒè¯ä¸€ä¸‹0.1çš„æ•ˆæœ
            metrics_at_01 = evaluate_at_threshold(coco_gt, dets, cls_id, 0.1)
            
            optimal_thresholds[str(cls_id)] = 0.1
            analysis_results.append([
                cls_id, cls_name, len(dets), 0.1,
                metrics_at_01['ap'], metrics_at_01['ar'], metrics_at_01['f1'],
                f"ä¸­ç­‰ç½®ä¿¡åº¦(max={max_score:.3f})"
            ])
            medium_count += 1
            continue
        
        # æƒ…å†µ5ï¼šæœ€é«˜ç½®ä¿¡åº¦é«˜ (>0.2)ï¼Œè¿›è¡Œé˜ˆå€¼ä¼˜åŒ–
        print(f"  âœ… æœ€é«˜ç½®ä¿¡åº¦ > {OPTIMIZE_THRESHOLD}ï¼Œè¿›è¡Œé˜ˆå€¼ä¼˜åŒ–")
        print("  æ‰«æé˜ˆå€¼: ", end="")
        
        best_f1 = -1  # åˆå§‹åŒ–ä¸º-1ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°æ›´å¥½çš„
        best_thr = DEFAULT_THRESHOLD
        best_metrics = {'ap': 0.0, 'ar': 0.0, 'f1': 0.0}  # åˆå§‹åŒ–ä¸ºé»˜è®¤å€¼
        
        for thr in scan_thresholds:
            thr = round(thr, 2)
            metrics = evaluate_at_threshold(coco_gt, dets, cls_id, thr)
            
            if metrics['f1'] > best_f1:
                best_f1 = metrics['f1']
                best_thr = thr
                best_metrics = metrics
            
            print(".", end="", flush=True)
        
        print(f" âœ“")
        
        # ç¡®ä¿best_metricsä¸ä¸ºNone
        if best_metrics is None:
            best_metrics = {'ap': 0.0, 'ar': 0.0, 'f1': 0.0}
        
        optimal_thresholds[str(cls_id)] = best_thr
        analysis_results.append([
            cls_id, cls_name, len(dets), best_thr,
            best_metrics['ap'], best_metrics['ar'], best_metrics['f1'],
            "ä¼˜åŒ–"
        ])
        optimize_count += 1
        high_conf_classes.append(f"{cls_name}(max={max_score:.3f}->thr={best_thr:.2f}, AP={best_metrics['ap']:.3f})")
        
        print(f"  âœ… æœ€ä¼˜é˜ˆå€¼: {best_thr:.2f} "
              f"(AP={best_metrics['ap']:.3f}, "
              f"AR={best_metrics['ar']:.3f}, "
              f"F1={best_metrics['f1']:.3f})")
    
    # ä¿å­˜æœ€ä¼˜é˜ˆå€¼
    thresh_path = os.path.join(OUTPUT_DIR, 'optimal_thresholds.json')
    with open(thresh_path, 'w') as f:
        json.dump(optimal_thresholds, f, indent=2)
    
    print(f"\nâœ… æœ€ä¼˜é˜ˆå€¼å·²ä¿å­˜: {thresh_path}")
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    headers = ["ID", "ç±»åˆ«", "æ¡†æ•°", "é˜ˆå€¼", "AP", "AR", "F1", "çŠ¶æ€"]
    
    # æŒ‰çŠ¶æ€æ’åº
    def sort_key(x):
        if x[7] == "ä¼˜åŒ–":
            return (0, -x[3] if isinstance(x[3], (int, float)) else 0)
        elif "ä¸­ç­‰" in x[7]:
            return (1, -x[3] if isinstance(x[3], (int, float)) else 0)
        else:
            return (2, -x[3] if isinstance(x[3], (int, float)) else 0)
    
    analysis_results.sort(key=sort_key)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š åŠ¨æ€é˜ˆå€¼ä¼˜åŒ–ç»“æœ")
    print("=" * 80)
    print(tabulate(analysis_results, headers=headers, tablefmt="grid", floatfmt=".3f"))
    
    # ç»Ÿè®¡æ‘˜è¦
    print(f"\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
    print(f"  ä¼˜åŒ–ç±»åˆ« (>{OPTIMIZE_THRESHOLD}): {optimize_count}")
    print(f"  ä¸­ç­‰ç½®ä¿¡åº¦ç±»åˆ« (0.1-0.2): {medium_count}")
    print(f"  ä½ç½®ä¿¡åº¦ç±»åˆ« (<0.1/æ¡†å°‘): {low_count}")
    print(f"  æ— æ£€æµ‹æ¡†ç±»åˆ«: {no_box_count}")
    
    if high_conf_classes:
        print(f"\nâœ… ä¼˜åŒ–çš„ç±»åˆ«:")
        for cls_info in high_conf_classes:
            print(f"  {cls_info}")
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    report_path = os.path.join(OUTPUT_DIR, 'threshold_optimization_report.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("é˜ˆå€¼ä¼˜åŒ–åˆ†ææŠ¥å‘Š (æ–¹æ¡ˆCï¼šåŠ¨æ€é˜ˆå€¼)\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"é»˜è®¤é˜ˆå€¼: {DEFAULT_THRESHOLD}\n")
        f.write(f"ä¼˜åŒ–é˜ˆå€¼çº¿: {OPTIMIZE_THRESHOLD}\n")
        f.write(f"æœ€å°‘æ¡†æ•°: {MIN_BOXES}\n\n")
        f.write(tabulate(analysis_results, headers=headers, tablefmt="grid", floatfmt=".3f"))
        f.write(f"\n\nç»Ÿè®¡æ‘˜è¦:\n")
        f.write(f"  ä¼˜åŒ–ç±»åˆ«: {optimize_count}\n")
        f.write(f"  ä¸­ç­‰ç½®ä¿¡åº¦ç±»åˆ«: {medium_count}\n")
        f.write(f"  ä½ç½®ä¿¡åº¦ç±»åˆ«: {low_count}\n")
        f.write(f"  æ— æ£€æµ‹æ¡†ç±»åˆ«: {no_box_count}\n")
    
    print(f"\nâœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    return optimal_thresholds

if __name__ == "__main__":
    # ç¡®ä¿tabulateå·²å®‰è£…
    try:
        from tabulate import tabulate
    except ImportError:
        import subprocess
        subprocess.check_call(["pip", "install", "tabulate"])
        from tabulate import tabulate
    
    optimize_thresholds_dynamic()