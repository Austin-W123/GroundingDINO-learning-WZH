"""
æœ€ä¼˜é˜ˆå€¼ç»Ÿè®¡è„šæœ¬ï¼ˆç®€åŒ–ç¾è§‚ç‰ˆï¼‰
ä»æ£€æµ‹ç»“æœä¸­ä¸ºæ¯ä¸ªç±»åˆ«æ‰¾åˆ°æœ€ä¼˜é˜ˆå€¼
è¾“å‡ºï¼šæ¸…æ™°è¡¨æ ¼ + JSONæ–‡ä»¶
"""
import os
import json
import numpy as np
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
from tabulate import tabulate  

# é…ç½®
COCO_ANNO_PATH = "D:/groundingdino_work/GroundingDINO-main/data/coco/annotations/instances_val2017.json"
DETECTION_RESULT = "D:/groundingdino_work/GroundingDINO-main/results/coco_seen_400imgs_prompt1.json"
OUTPUT_DIR = "D:/groundingdino_work/GroundingDINO-main/results"
OUTPUT_THRESHOLDS = os.path.join(OUTPUT_DIR, "best_thresholds.json")
OUTPUT_REPORT = os.path.join(OUTPUT_DIR, "threshold_analysis.txt")

# ç±»åˆ«åç§°æ˜ å°„
CLASS_NAMES = {
    1: "person", 2: "bicycle", 3: "car", 4: "motorcycle", 5: "airplane",
    6: "bus", 7: "train", 8: "truck", 9: "boat", 10: "traffic light",
    11: "fire hydrant", 13: "stop sign", 14: "parking meter", 15: "bench",
    16: "bird", 17: "cat", 18: "dog", 19: "horse", 20: "sheep",
    21: "cow", 22: "elephant", 23: "bear", 24: "zebra", 25: "giraffe",
    27: "backpack", 28: "umbrella", 31: "handbag", 32: "tie", 33: "suitcase",
    34: "frisbee", 35: "skis", 36: "snowboard", 37: "sports ball", 38: "kite",
    39: "baseball bat", 40: "baseball glove", 41: "skateboard", 42: "surfboard",
    43: "tennis racket", 44: "bottle", 46: "wine glass", 47: "cup", 48: "fork",
    49: "knife", 50: "spoon", 51: "bowl", 52: "banana", 53: "apple",
    54: "sandwich", 55: "orange", 56: "broccoli", 57: "carrot", 58: "hot dog",
    59: "pizza", 60: "donut", 61: "cake", 62: "chair", 63: "couch",
    64: "potted plant", 65: "bed", 67: "dining table", 70: "toilet",
    72: "tv", 73: "laptop", 74: "mouse", 75: "remote", 76: "keyboard",
    77: "cell phone", 78: "microwave", 79: "oven", 80: "toaster", 81: "sink",
    82: "refrigerator", 84: "book", 85: "clock", 86: "vase", 87: "scissors",
    88: "teddy bear", 89: "hair drier", 90: "toothbrush"
}

def analyze_thresholds():
    """åˆ†ææ¯ä¸ªç±»åˆ«çš„æœ€ä¼˜é˜ˆå€¼"""
    print("=" * 80)
    print("æœ€ä¼˜é˜ˆå€¼ç»Ÿè®¡å·¥å…· v1.0")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½æ•°æ®ä¸­...")
    coco_gt = COCO(COCO_ANNO_PATH)
    with open(DETECTION_RESULT, 'r') as f:
        results = json.load(f)
    print(f"  æ£€æµ‹ç»“æœæ–‡ä»¶: {DETECTION_RESULT}")
    print(f"  æ€»æ£€æµ‹æ¡†æ•°: {len(results)}")
    
    # æŒ‰ç±»åˆ«åˆ†ç»„
    cls_results = {}
    for det in results:
        cls_id = det['category_id']
        if cls_id not in cls_results:
            cls_results[cls_id] = []
        cls_results[cls_id].append(det)
    
    print(f"  æœ‰æ£€æµ‹ç»“æœçš„ç±»åˆ«æ•°: {len(cls_results)}")
    print("\n" + "=" * 80)
    
    # å­˜å‚¨ç»“æœ
    best_thresholds = {}
    analysis_results = []
    
    # å¯¹æ¯ä¸ªç±»åˆ«åˆ†æ
    threshold_range = np.arange(0.1, 0.51, 0.05)
    
    for idx, (cls_id, dets) in enumerate(sorted(cls_results.items()), 1):
        cls_name = CLASS_NAMES.get(cls_id, f"Unknown({cls_id})")
        print(f"\n[{idx:2d}/{len(cls_results)}] åˆ†æç±»åˆ«: {cls_name} (ID: {cls_id})")
        print(f"  æ£€æµ‹æ¡†æ•°é‡: {len(dets)}")
        
        best_f1 = 0
        best_thr = 0.25
        best_stats = None
        
        # è¿›åº¦æ¡
        print("  é˜ˆå€¼æ‰«æ: ", end="")
        
        for thr in threshold_range:
            thr = round(thr, 2)
            filtered_dets = [d for d in dets if d['score'] >= thr]
            
            if len(filtered_dets) < 3:
                print(".", end="", flush=True)
                continue
            
            try:
                coco_dt = coco_gt.loadRes(filtered_dets)
                coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')
                coco_eval.params.catIds = [cls_id]
                coco_eval.evaluate()
                coco_eval.accumulate()
                
                # è·å–ç²¾ç¡®ç‡å’Œå¬å›ç‡
                prec = coco_eval.eval['precision'][0, :, 0, 0, 2]
                rec = coco_eval.eval['recall'][0, :, 0, 2]
                
                prec = prec[prec > -1]
                rec = rec[rec > -1]
                
                if len(prec) > 0 and len(rec) > 0:
                    avg_prec = np.mean(prec)
                    avg_rec = np.mean(rec)
                    
                    if avg_prec + avg_rec > 0:
                        f1 = 2 * avg_prec * avg_rec / (avg_prec + avg_rec)
                        
                        if f1 > best_f1:
                            best_f1 = f1
                            best_thr = thr
                            best_stats = (avg_prec, avg_rec, f1)
                
                print("*", end="", flush=True)
            except:
                print(".", end="", flush=True)
        
        print(" âœ“")
        
        # è®°å½•æœ€ä½³ç»“æœ
        best_thresholds[str(cls_id)] = best_thr
        if best_stats:
            analysis_results.append([
                cls_id, 
                cls_name, 
                len(dets),
                best_thr,
                f"{best_stats[0]:.3f}",
                f"{best_stats[1]:.3f}",
                f"{best_stats[2]:.3f}"
            ])
            print(f"  âœ… æœ€ä¼˜é˜ˆå€¼: {best_thr:.2f} (Prec={best_stats[0]:.3f}, Rec={best_stats[1]:.3f}, F1={best_stats[2]:.3f})")
        else:
            analysis_results.append([cls_id, cls_name, len(dets), best_thr, "-", "-", "-"])
            print(f"  âš ï¸ é»˜è®¤é˜ˆå€¼: {best_thr:.2f} (æ— æœ‰æ•ˆæ•°æ®)")
    
    # ä¿å­˜JSON
    with open(OUTPUT_THRESHOLDS, 'w') as f:
        json.dump(best_thresholds, f, indent=2)
    print(f"\nâœ… é˜ˆå€¼é…ç½®æ–‡ä»¶å·²ä¿å­˜: {OUTPUT_THRESHOLDS}")
    
    # ç”Ÿæˆç¾è§‚è¡¨æ ¼
    headers = ["ID", "ç±»åˆ«åç§°", "æ£€æµ‹æ¡†æ•°", "æœ€ä¼˜é˜ˆå€¼", "ç²¾ç¡®ç‡", "å¬å›ç‡", "F1åˆ†æ•°"]
    
    # æŒ‰é˜ˆå€¼æ’åº
    analysis_results.sort(key=lambda x: x[3] if isinstance(x[3], (int, float)) else 0, reverse=True)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š æœ€ä¼˜é˜ˆå€¼ç»Ÿè®¡ç»“æœ (æŒ‰é˜ˆå€¼ä»é«˜åˆ°ä½æ’åº)")
    print("=" * 80)
    print(tabulate(analysis_results, headers=headers, tablefmt="grid", numalign="center"))
    
    # ç»Ÿè®¡æ‘˜è¦
    thresholds = [r[3] for r in analysis_results if isinstance(r[3], (int, float))]
    print("\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
    print(f"  å¹³å‡é˜ˆå€¼: {np.mean(thresholds):.3f}")
    print(f"  ä¸­ä½æ•°é˜ˆå€¼: {np.median(thresholds):.3f}")
    print(f"  æœ€å°é˜ˆå€¼: {np.min(thresholds):.3f}")
    print(f"  æœ€å¤§é˜ˆå€¼: {np.max(thresholds):.3f}")
    
    # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
    with open(OUTPUT_REPORT, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("æœ€ä¼˜é˜ˆå€¼ç»Ÿè®¡åˆ†ææŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"æ£€æµ‹ç»“æœæ–‡ä»¶: {DETECTION_RESULT}\n")
        f.write(f"æ€»æ£€æµ‹æ¡†æ•°: {len(results)}\n")
        f.write(f"æœ‰æ£€æµ‹ç»“æœçš„ç±»åˆ«æ•°: {len(cls_results)}\n\n")
        
        f.write(tabulate(analysis_results, headers=headers, tablefmt="grid", numalign="center"))
        
        f.write("\n\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:\n")
        f.write(f"  å¹³å‡é˜ˆå€¼: {np.mean(thresholds):.3f}\n")
        f.write(f"  ä¸­ä½æ•°é˜ˆå€¼: {np.median(thresholds):.3f}\n")
        f.write(f"  æœ€å°é˜ˆå€¼: {np.min(thresholds):.3f}\n")
        f.write(f"  æœ€å¤§é˜ˆå€¼: {np.max(thresholds):.3f}\n")
    
    print(f"\nâœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {OUTPUT_REPORT}")
    print("=" * 80)
    print("\nğŸ“ ç”Ÿæˆæ–‡ä»¶æ±‡æ€»:")
    print(f"  1. é˜ˆå€¼é…ç½®æ–‡ä»¶: {OUTPUT_THRESHOLDS}")
    print(f"  2. åˆ†ææŠ¥å‘Š: {OUTPUT_REPORT}")

if __name__ == "__main__":
    import os
    # å®‰è£…tabulateï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
    try:
        from tabulate import tabulate
    except ImportError:
        print("æ­£åœ¨å®‰è£… tabulate...")
        import subprocess
        subprocess.check_call(["pip", "install", "tabulate"])
        from tabulate import tabulate
    
    analyze_thresholds()